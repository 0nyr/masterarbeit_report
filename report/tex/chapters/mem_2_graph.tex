\chapter{Converting memory dumps to graphs}\label{chap:mem_2_graph}
Now that we have a decent understanding of the dataset as well as the low level memory dump format, we can start to think about how to convert the memory dumps into graphs. As a recall, we want to be able to convert a memory dump into a graph representation that can be used for machine learning, since we want to be able to create a memory modelization as a basis for efficient embedding and feature engineering later. This is inherently due to the imbalanceness of the dataset, as we want to add more information to each memory block that just its raw bytes. The goal is to have a graph representation of the memory dump that can be used for efficient machine learning.

This section will be dedicated to describe the methods developped around this problem. We will first discuss the design of the graph representation, then we will discuss the implementation of the graph construction process. Finally, we will discuss the semantic embedding of the graph, which is the process of adding more information to the graph.

\section{Initial work from Python to Rust}

\subsection{First steps}
    Initially, we have been working and manipulating the code provided by SmartKex\footnote{SmartKex GitHub repository: \url{https://github.com/smartvmi/Smart-and-Naive-SSH-Key-Extraction}} for key detection. Our first explorations of the dataset quickly gave birth to some Jupyter Notebooks, which were used to explore the dataset and to understand the code, like \texttt{search\_in\_heap\_mem.ipynb}. Rapidly, we decided to rebuild a complete Python 3.11 version of the code. This was done for several reasons:

    \begin{itemize}
        \item The original code has no type hinting, which makes it hard to read and understand.
        \item We wanted to explore the dataset and learn by doing.
        \item The original code was not designed to be used as a library, but rather as a standalone script.
        \item The original code was just a few hundred lines of code and was not designed to be easily extensible, nor to be able to handle a large number of memory dumps.
    \end{itemize}

    We decided to build a memory graph representation at that moment because we wanted to be able to add more information to the memory blocks than just their raw bytes. This new program was called \texttt{ssh\_key\_discover}, and relied on a number of Python libraries to work, like \texttt{graphviz}. This was a all-in-one library, composed of 2 sections, \texttt{mem\_graph} and \texttt{ml\_discovery}. The first one is dedicated to building the memory graph, while the second one is dedicated to the data science and machine learning part.

    This initial program was already capable of handling several data processing pipelines, including machine learning pipelines with models like Random Forest, a grid search for hyperparameter optimization, and a cross validation pipeline, several balancing strategies and of course, a memory graph representation and semantic embedding. As an early development version, this program was not optimized for performance, and just loading a given heap dump file and its annotation, and then building the memory graph representation, could take from 30 seconds to a minute (on the TUXEDO machine), depending on the size of the heap dump file. As we are dealing with more that $ 10^{6} $ files, a rapid estimation of the time needed just for the semantic embedding of the memory graph representation was above a month. In this regard, this initial program was just used on a bunch of files as a way to develop the semantic embedding model, algorithm and start working on feature engineering and machine learning.
    
    This optimization issue was clearly not acceptable, and we decided to rewrite the graph part in Rust, which is a compiled language, and thus, several order of magnitude faster than Python. This was also a good opportunity to learn Rust, which is a language that is gaining more and more popularity, especially in the security community. This new program was called \texttt{mem2graph}. Switching from Rust to Python and doing a proper use of multithreading allowed us to reduce the time needed to build the memory graph representation from 30 seconds to less than 1 second. In out case, and comparing using only the TUXEDO laptop, this represent an estimated minimum of a 130x speedup. But this is even much better on the server, where the multithreading can really be leverage. This was a huge improvement, and allowed us to build the memory graph representation for the whole dataset in a just a few hours.

\section{Memory Graph Representation}
Now, let's describe the memory graph representation. The goal is to be able to represent a memory dump as a graph. This modelization makes sense since the heap dump can be considered as having data structures as nodes, being connected by pointers acting as arrows. This is a very natural way to represent a memory dump. However in our cases, and since the goal is to make predictions on raw bytes, we will not use the data structures as nodes, but rather the memory blocks directly. This is because we want to be able to make predictions on raw bytes, and not on data structures. 

% introduce the type of the graph, the nodes and edge

\subsection{Graph Construction}
% graph construction algorithm
% graph annotation algorithm

\subsection{Exporting the Graph}
% the DOT format


\begin{minipage}{\dimexpr\linewidth-20pt}
    Here are the constants define for memory format conversion in the Rust code:

   %\begin{lstlisting}[language=json, , label={lst:json}]
   \begin{lstlisting}[style=rust, caption={Rust memory format constants in \textit{mem2graph}}]
    pub const BLOCK_BYTE_SIZE: usize = 8; // 64-bit, ex: C0 03 7B 09 2A 56 00 00
    pub const PTR_ENDIANNESS: Endianness = Endianness::Little;
    pub const MALLOC_HEADER_ENDIANNESS: Endianness = Endianness::Little;
   \end{lstlisting}
\end{minipage}

\subsection{Semantic Embedding}\label{sec:mem_2_graph:semantic_embedding}
% semantic embedding algorithm
% the CSV embedding format
